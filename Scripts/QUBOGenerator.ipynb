{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8500ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "from math import prod\n",
    "from qiskit_optimization.translators import from_docplex_mp\n",
    "from docplex.mp.model import Model\n",
    "from dimod import BinaryQuadraticModel\n",
    "import dimod\n",
    "from math import inf\n",
    "from dadk.BinPol import BinPol\n",
    "from dadk.QUBOSolverCPU import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa98164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum energy saving possible by avoiding costs is given by the sum over maximum intermediate cardinalities\n",
    "def get_penalty_value(card):\n",
    "    sorted_card = -np.sort(-np.array(card))\n",
    "    penalty_value = 0\n",
    "    for j in range(1, len(sorted_card)-1):\n",
    "        penalty_value = penalty_value + sum(sorted_card[i] for i in np.arange(j+1))\n",
    "    return penalty_value\n",
    "\n",
    "def get_log_values(coeff, num_decimal_pos, use_rounding=True):\n",
    "    if use_rounding:\n",
    "        log_coeff = np.around(np.log10(coeff), num_decimal_pos)\n",
    "    else:\n",
    "        log_coeff = np.log10(coeff)\n",
    "    return log_coeff.tolist()\n",
    "\n",
    "## Computes and returns the logarithmic maximum intermediate cardinality for the join corresponding to the given join_index based\n",
    "## on the given sorted_card list\n",
    "def get_maximum_log_intermediate_outer_operand_cardinality(join_index, card):\n",
    "    sorted_card = sorted(card, reverse=True)\n",
    "    return sum(sorted_card[i] for i in range(join_index+2))\n",
    "\n",
    "def is_thres_reachable_for_join(join_index, card, log_thres):\n",
    "    max_log_card = get_maximum_log_intermediate_outer_operand_cardinality(join_index, card)\n",
    "    return max_log_card > log_thres\n",
    "\n",
    "def get_binary_slack_coeff(num_slack, precision):\n",
    "    slack_coeff = []\n",
    "    for i in range(num_slack):\n",
    "        slack_coeff.append(pow(2, i))\n",
    "    slack_coeff = [x * precision for x in slack_coeff]\n",
    "    return slack_coeff\n",
    "\n",
    "def get_binary_slack_variables_for_bound(model, bound, num_decimal_pos):\n",
    "    precision = pow(0.1, num_decimal_pos)\n",
    "    num_slack = int(math.floor(np.log2(bound/precision))) + 1\n",
    "    slack = model.binary_var_list(num_slack)\n",
    "    return slack, get_binary_slack_coeff(num_slack, precision)\n",
    "\n",
    "def get_slack_variables_for_bound(model, bound, num_decimal_pos):\n",
    "    precision = pow(0.1, num_decimal_pos)\n",
    "    num_variables = int(bound*precision)\n",
    "    slack = model.binary_var_list(num_variables)\n",
    "    return slack, np.arange(1, num_variables+1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e1eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_IBMQ_QUBO_for_left_deep_trees(card, pred, pred_sel, log_thres, num_decimal_pos, penalty_scaling=1):\n",
    "    \n",
    "    #thres_penalty = [x / thres[0] for x in thres]\n",
    "    #thres_penalty = [x / thres[len(thres)-1] for x in thres]\n",
    "    \n",
    "    card = get_log_values(card, num_decimal_pos)\n",
    "    pred_sel = get_log_values(pred_sel, num_decimal_pos)\n",
    "    #log_thres = get_log_values(thres, num_decimal_pos)\n",
    "    \n",
    "    print(\"Card:\")\n",
    "    print(card)\n",
    "    print(\"Pred sel:\")\n",
    "    print(pred_sel)\n",
    "    \n",
    "    model = Model('docplex_model')\n",
    "    \n",
    "    num_relations = len(card)\n",
    "    num_pred = len(pred_sel)\n",
    "    num_joins = len(card) - 2\n",
    "\n",
    "    #v = model.binary_var_list(num_relations * num_joins)\n",
    "    v = model.binary_var_matrix(num_relations, num_joins)\n",
    "    \n",
    "    b = np.arange(2, num_joins+2).tolist()\n",
    "    \n",
    "    # Incentivise that the right number of relations is present for every join (i.e., 2 for join 1, 3 for join 2, ...)\n",
    "    H_A = model.sum((b[j] - model.sum(v[(t, j)] for t in range(num_relations)))**2 for j in range(num_joins))\n",
    "    \n",
    "    # Incentivise that, once joined, a relation is always part of subsequent joins\n",
    "    H_B = model.sum(model.sum(v[(t, j-1)] - v[(t, j-1)]*v[(t, j)] for j in range(1, num_joins)) for t in range(num_relations))\n",
    "    \n",
    "    # Incentivise that a predicate is only applicable for a join if both associated relations are present\n",
    "    pred_vars = model.binary_var_matrix(num_pred, num_joins)\n",
    "    H_pred_a = model.sum(model.sum(pred_vars[(p, j)] - pred_vars[(p, j)] *v[(pred[p][0], j)] for p in range(num_pred)) for j in range(num_joins))\n",
    "    H_pred_b = model.sum(model.sum(pred_vars[(p, j)] - pred_vars[(p, j)] *v[(pred[p][1], j)] for p in range(num_pred)) for j in range(num_joins))\n",
    "    H_pred = H_pred_a + H_pred_b\n",
    "    \n",
    "    H_cost = 0\n",
    "    penalty_weight = 0\n",
    "    \n",
    "    # Intermediate cardinality calculation\n",
    "    for j in range(num_joins):\n",
    "        #max_log_card = get_maximum_log_intermediate_outer_operand_cardinality(j, card)\n",
    "        #penalty_weight = penalty_weight + pow(max_log_card - log_thres, 2)\n",
    "        penalty_weight = penalty_weight + 1\n",
    "        slack, slack_coeff = get_binary_slack_variables_for_bound(model, log_thres, num_decimal_pos)\n",
    "        H_thres = (model.sum(slack_coeff[s] * slack[s] for s in range(len(slack))) - (model.sum(card[t]*v[(t, j)] for t in range(num_relations)) + model.sum(pred_sel[p] * pred_vars[(p, j)] for p in range(num_pred))))**2\n",
    "        H_cost = H_cost + H_thres\n",
    "    \n",
    "    print(\"Vanilla penalty weight: \" + str(penalty_weight))\n",
    "    penalty_weight = penalty_weight * penalty_scaling\n",
    "    \n",
    "    H_valid = H_A + H_B + H_pred\n",
    "    \n",
    "    H = penalty_weight * H_valid + H_cost\n",
    "    \n",
    "    model.minimize(H)\n",
    "\n",
    "    qubo = from_docplex_mp(model)\n",
    "    \n",
    "    return qubo, penalty_weight\n",
    "\n",
    "def generate_DWave_QUBO_for_left_deep_trees(card, pred, pred_sel, thres, num_decimal_pos, penalty_scaling=1):\n",
    "    ibmq_qubo, penalty_weight = generate_IBMQ_QUBO_for_left_deep_trees(card, pred, pred_sel, thres, num_decimal_pos, penalty_scaling=penalty_scaling)\n",
    "    dwave_qubo = dimod.as_bqm(ibmq_qubo.objective.linear.to_array(), ibmq_qubo.objective.quadratic.to_array(), ibmq_qubo.objective.constant, dimod.BINARY)\n",
    "    return dwave_qubo, penalty_weight\n",
    "\n",
    "def generate_Fujitsu_QUBO_for_left_deep_trees(card, pred, pred_sel, thres, num_decimal_pos, penalty_scaling=1):\n",
    "    ibmq_qubo, penalty_weight = generate_IBMQ_QUBO_for_left_deep_trees(card, pred, pred_sel, thres, num_decimal_pos, penalty_scaling=penalty_scaling)\n",
    "    num_qubits = len(ibmq_qubo.objective.linear.to_array())\n",
    "    qubo_matrix_array = np.zeros((num_qubits, num_qubits))\n",
    "    dwave_qubo = dimod.as_bqm(ibmq_qubo.objective.linear.to_array(), ibmq_qubo.objective.quadratic.to_array(), ibmq_qubo.objective.constant, dimod.BINARY)\n",
    "    quadratic, offset = dwave_qubo.to_qubo()\n",
    "    for ((i, j), bias) in quadratic.items():\n",
    "        qubo_matrix_array[i][j] = bias\n",
    "        qubo_matrix_array[j][i] = bias\n",
    "    fujitsu_qubo = BinPol(qubo_matrix_array=qubo_matrix_array, constant=ibmq_qubo.objective.constant)\n",
    "    return fujitsu_qubo, penalty_weight\n",
    "\n",
    "# Current version of left-deep QUBO, supporting multiple thresholds\n",
    "def generate_legacy_IBMQ_QUBO_for_left_deep_trees(card, pred, pred_sel, log_thres, num_decimal_pos):\n",
    "    \n",
    "    thres = np.around(np.power(10, log_thres))\n",
    "    \n",
    "    card = get_log_values(card, num_decimal_pos)\n",
    "    pred_sel = get_log_values(pred_sel, num_decimal_pos)\n",
    "    #log_thres = get_log_values(thres, num_decimal_pos)\n",
    "    \n",
    "    print(\"Card:\")\n",
    "    print(card)\n",
    "    print(\"Pred sel:\")\n",
    "    print(pred_sel)\n",
    "    \n",
    "    model = Model('docplex_model')\n",
    "    \n",
    "    num_relations = len(card)\n",
    "    num_pred = len(pred_sel)\n",
    "    num_joins = len(card) - 2\n",
    "\n",
    "    #v = model.binary_var_list(num_relations * num_joins)\n",
    "    v = model.binary_var_matrix(num_relations, num_joins)\n",
    "    \n",
    "    b = np.arange(2, num_joins+2).tolist()\n",
    "    \n",
    "    # Incentivise that the right number of relations is present for every join (i.e., 2 for join 1, 3 for join 2, ...)\n",
    "    H_A = model.sum((b[j] - model.sum(v[(t, j)] for t in range(num_relations)))**2 for j in range(num_joins))\n",
    "    \n",
    "    # Incentivise that, once joined, a relation is always part of subsequent joins\n",
    "    H_B = model.sum(model.sum(v[(t, j-1)] - v[(t, j-1)]*v[(t, j)] for j in range(1, num_joins)) for t in range(num_relations))\n",
    "    \n",
    "    # Incentivise that a predicate is only applicable for a join if both associated relations are present\n",
    "    pred_vars = model.binary_var_matrix(num_pred, num_joins)\n",
    "    H_pred_a = model.sum(model.sum(pred_vars[(p, j)] - pred_vars[(p, j)] *v[(pred[p][0], j)] for p in range(num_pred)) for j in range(num_joins))\n",
    "    H_pred_b = model.sum(model.sum(pred_vars[(p, j)] - pred_vars[(p, j)] *v[(pred[p][1], j)] for p in range(num_pred)) for j in range(num_joins))\n",
    "    H_pred = H_pred_a + H_pred_b\n",
    "    \n",
    "    thres_vars = model.binary_var_matrix(len(log_thres), num_joins)\n",
    "    \n",
    "    # Intermediate cardinality calculation\n",
    "    H_thres = 0\n",
    "    H_cost = 0\n",
    "    penalty_weight = 0\n",
    "    for r in range(len(log_thres)):\n",
    "        for j in range(num_joins):\n",
    "            max_log_card = get_maximum_log_intermediate_outer_operand_cardinality(j, card)\n",
    "            \n",
    "            penalty_weight = penalty_weight + thres[r]\n",
    "            large_constant = max_log_card - log_thres[r]\n",
    "            slack, slack_coeff = get_binary_slack_variables_for_bound(model, max_log_card, num_decimal_pos)\n",
    "            \n",
    "            H_thres = H_thres + ((model.sum(card[t]*v[(t, j)] for t in range(num_relations)) + model.sum(pred_sel[p] * pred_vars[(p, j)] for p in range(num_pred))) - large_constant*thres_vars[(r, j)] - log_thres[r] + model.sum(slack_coeff[s] * slack[s] for s in range(len(slack))))**2\n",
    "            H_cost = H_cost + thres_vars[(r, j)]*thres[r]\n",
    "    \n",
    "    # Calculate final penalty weight\n",
    "    precision = pow(0.1, num_decimal_pos)\n",
    "    epsilon = 0.25\n",
    "    penalty_weight = (penalty_weight / pow(precision, 2)) + epsilon\n",
    "        \n",
    "    H_valid = H_A + H_B + H_pred + H_thres\n",
    "    \n",
    "    H = penalty_weight * H_valid + H_cost\n",
    "    \n",
    "    model.minimize(H)\n",
    "\n",
    "    qubo = from_docplex_mp(model)\n",
    "    \n",
    "    return qubo, penalty_weight\n",
    "\n",
    "def generate_legacy_DWave_QUBO_for_left_deep_trees(card, pred, pred_sel, thres, num_decimal_pos):\n",
    "    ibmq_qubo, penalty_weight = generate_legacy_IBMQ_QUBO_for_left_deep_trees(card, pred, pred_sel, thres, num_decimal_pos)\n",
    "    dwave_qubo = dimod.as_bqm(ibmq_qubo.objective.linear.to_array(), ibmq_qubo.objective.quadratic.to_array(), ibmq_qubo.objective.constant, dimod.BINARY)\n",
    "    return dwave_qubo, penalty_weight\n",
    "\n",
    "def generate_legacy_Fujitsu_QUBO_for_left_deep_trees(card, pred, pred_sel, thres, num_decimal_pos):\n",
    "    ibmq_qubo, penalty_weight = generate_legacy_IBMQ_QUBO_for_left_deep_trees2(card, pred, pred_sel, thres, num_decimal_pos)\n",
    "    num_qubits = len(ibmq_qubo.objective.linear.to_array())\n",
    "    qubo_matrix_array = np.zeros((num_qubits, num_qubits))\n",
    "    dwave_qubo = dimod.as_bqm(ibmq_qubo.objective.linear.to_array(), ibmq_qubo.objective.quadratic.to_array(), ibmq_qubo.objective.constant, dimod.BINARY)\n",
    "    quadratic, offset = dwave_qubo.to_qubo()\n",
    "    for ((i, j), bias) in quadratic.items():\n",
    "        qubo_matrix_array[i][j] = bias\n",
    "        qubo_matrix_array[j][i] = bias\n",
    "    fujitsu_qubo = BinPol(qubo_matrix_array=qubo_matrix_array, constant=ibmq_qubo.objective.constant)\n",
    "    return fujitsu_qubo, penalty_weight\n",
    "\n",
    "# QUBO version without any thresholds, relying purely on quadratic approximation\n",
    "def generate_IBMQ_QUBO_for_left_deep_trees_v2(card, pred, pred_sel, penalty_scaling=1):\n",
    "    \n",
    "    card = get_log_values(card, 0, use_rounding=False)\n",
    "    pred_sel = get_log_values(pred_sel, 0, use_rounding=False)\n",
    "    \n",
    "    print(\"Card:\")\n",
    "    print(card)\n",
    "    print(\"Pred sel:\")\n",
    "    print(pred_sel)\n",
    "    \n",
    "    model = Model('docplex_model')\n",
    "    \n",
    "    num_relations = len(card)\n",
    "    num_pred = len(pred_sel)\n",
    "    num_joins = len(card) - 2\n",
    "\n",
    "    #v = model.binary_var_list(num_relations * num_joins)\n",
    "    v = model.binary_var_matrix(num_relations, num_joins)\n",
    "    \n",
    "    b = np.arange(2, num_joins+2).tolist()\n",
    "    \n",
    "    # Incentivise that the right number of relations is present for every join (i.e., 2 for join 1, 3 for join 2, ...)\n",
    "    H_A = model.sum((b[j] - model.sum(v[(t, j)] for t in range(num_relations)))**2 for j in range(num_joins))\n",
    "    \n",
    "    # Incentivise that, once joined, a relation is always part of subsequent joins\n",
    "    H_B = model.sum(model.sum(v[(t, j-1)] - v[(t, j-1)]*v[(t, j)] for j in range(1, num_joins)) for t in range(num_relations))\n",
    "    \n",
    "    # Incentivise that a predicate is only applicable for a join if both associated relations are present\n",
    "    pred_vars = model.binary_var_matrix(num_pred, num_joins)\n",
    "    H_pred_a = model.sum(model.sum(pred_vars[(p, j)] - pred_vars[(p, j)] *v[(pred[p][0], j)] for p in range(num_pred)) for j in range(num_joins))\n",
    "    H_pred_b = model.sum(model.sum(pred_vars[(p, j)] - pred_vars[(p, j)] *v[(pred[p][1], j)] for p in range(num_pred)) for j in range(num_joins))\n",
    "    H_pred = H_pred_a + H_pred_b\n",
    "    \n",
    "    H_cost = 0\n",
    "    penalty_weight = 0\n",
    "    \n",
    "    # Intermediate cardinality calculation\n",
    "    for j in range(num_joins):\n",
    "        #max_log_card = get_maximum_log_intermediate_outer_operand_cardinality(j, card)\n",
    "        #penalty_weight = penalty_weight + pow(max_log_card - log_thres, 2)\n",
    "        penalty_weight = penalty_weight + 1\n",
    "        H_thres = (model.sum(card[t]*v[(t, j)] for t in range(num_relations)) + model.sum(pred_sel[p] * pred_vars[(p, j)] for p in range(num_pred)))**2\n",
    "        H_cost = H_cost + H_thres\n",
    "    \n",
    "    print(\"Vanilla penalty weight: \" + str(penalty_weight))\n",
    "    penalty_weight = penalty_weight * penalty_scaling\n",
    "    \n",
    "    H_valid = H_A + H_B + H_pred\n",
    "    \n",
    "    H = penalty_weight * H_valid + H_cost\n",
    "    \n",
    "    model.minimize(H)\n",
    "\n",
    "    qubo = from_docplex_mp(model)\n",
    "    \n",
    "    return qubo, penalty_weight\n",
    "\n",
    "def generate_DWave_QUBO_for_left_deep_trees_v2(card, pred, pred_sel, penalty_scaling=1):\n",
    "    ibmq_qubo, penalty_weight = generate_IBMQ_QUBO_for_left_deep_trees_v2(card, pred, pred_sel, penalty_scaling=penalty_scaling)\n",
    "    dwave_qubo = dimod.as_bqm(ibmq_qubo.objective.linear.to_array(), ibmq_qubo.objective.quadratic.to_array(), ibmq_qubo.objective.constant, dimod.BINARY)\n",
    "    return dwave_qubo, penalty_weight\n",
    "\n",
    "def generate_Fujitsu_QUBO_for_left_deep_trees_v2(card, pred, pred_sel, penalty_scaling=1):\n",
    "    ibmq_qubo, penalty_weight = generate_IBMQ_QUBO_for_left_deep_trees_v2(card, pred, pred_sel, penalty_scaling=penalty_scaling)\n",
    "    num_qubits = len(ibmq_qubo.objective.linear.to_array())\n",
    "    print(\"Number of IBM qubits: \" + str(num_qubits))\n",
    "    qubo_matrix_array = np.zeros((num_qubits, num_qubits))\n",
    "    dwave_qubo = dimod.as_bqm(ibmq_qubo.objective.linear.to_array(), ibmq_qubo.objective.quadratic.to_array(), ibmq_qubo.objective.constant, dimod.BINARY)\n",
    "    quadratic, offset = dwave_qubo.to_qubo()\n",
    "    for ((i, j), bias) in quadratic.items():\n",
    "        qubo_matrix_array[i][j] = bias\n",
    "        qubo_matrix_array[j][i] = bias\n",
    "    fujitsu_qubo = BinPol(qubo_matrix_array=qubo_matrix_array, constant=ibmq_qubo.objective.constant)\n",
    "    print(\"Number of Fujitsu qubits: \" + str(fujitsu_qubo.N))\n",
    "    return fujitsu_qubo, penalty_weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
